---
title: "Informative prior"
author: "Lifan Liang"
date: "2025-02-14"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Simulation

### Data generation

We selected 3365 SNPs from a random region (i.e. `chr9:2000000-3000000`) and extracted the corresponding genotype of the 100 cell lines in the neuron stimulation. All SNPs have minor allele frequency (MAF) over 1%. The heatmap below shows the genotype profiles of SNP (column). X were copied 9 times to be $X'$. So $X'$ has 1000 individuals, like 100 families within which there are 10 twins. Each twin receive different environmental exposures to generate Y. 

```{r}
library(pheatmap)
X <- t(readRDS("data/neuron_stim_genotype_chr9_2e6-3e6.rds")[,-1] )# Each row is a cell line
pheatmap(X,cluster_cols = F)
X1 <- t(matrix(rep(t(X),10),nrow=ncol(X)))
```



The SNPs were evenly split into 5 groups (673 SNPs per group). SNPs in each group has a different prior for being causal. But the causal SNPs have the same effect size. Let $Z_j$ be the group index for the $j_{th}$ SNP, $\gamma_j$ be whether the $j_{th}$ SNP is causal, and $X_ij$ be the genotype for the $i_{th}$ individual. The genetic effect for the $j_{th}$ SNP ($\beta_j$) is generated as follow:

$$
\gamma_j \sim Bernoulli(\pi_{Z_j})
\\
\beta_j|\gamma_j = 1 \sim N(0,\sigma^2)
\\
\beta_j|\gamma_j = 0 \sim \sigma_0
$$

where $\pi_k$ is the prior of being causal for the $k_{th}$ group, $\sigma$ is the effect size when the SNP is being causal, and $\sigma_0$ is the Dirac delta function.

In this simulation, we set ($\pi_k$) as $\{0.02\%, 0.04\%,0.08\%,0.16\%,0.32\%\}$. For the whole region, 0.124% ($\approx 4$) of the SNPs are expected to be causal. We set $\sigma=0.2$ and $\sigma_e=1.0$. Then we generated gene expression Y as:

$$
\epsilon \sim N(0,\sigma_e^2)
\\
Y_i = \sum_j X_{ij}\beta_j + \epsilon
$$

```{r}
#pi <- rep(c(2,4,8,16,32) * 1e-4, each=ncol(X)/5)
#pi <- rep(c(rep(2,9),50) * 1e-4, 400)[1:ncol(X)]
pi <- rep(2,ncol(X))
pi[sample(1:length(pi),168)] <- 100
pi <- pi * 1e-4
  
sim_group_pi <- function(X, pi=pi, sigma=0.25, sigma.e=1.0) {
  ### Impose the constraint that there is at least one causal SNP
  N <- 0
  while(N==0) {
    gamma <- rbinom(ncol(X),1,pi)
    N <- sum(gamma)
  }
  beta <- rnorm(ncol(X),sd=sigma) * gamma
  eps <- rnorm(nrow(X),sd=sigma.e)
  X <- scale(X, center=T, scale=T)
  Y <- drop(X %*% beta + eps)
  list(y=Y, X=X, pi=pi, gamma=gamma, beta=beta, eps=eps)
}

```

PVE varies because the genetic component of $var(Y)$ depends on the effect size and the allele frequency of causal SNPs. Mostly, the total PVE was less than 20%.

```{r}
set.seed(1234)
pve <- numeric(100L)
#rand.cor <- numeric(100L)
for(i in 1:length(pve)) {
  sim.res <- sim_group_pi(X1,pi)
  pve[i] <- 1 - sum(sim.res$eps**2) / sum((sim.res$y - mean(sim.res$y))**2)
  #rand.cor[i] <- max(abs(cor(sim.res$eps, sim.res$dat[,-1][,gamma!=0])))
}
boxplot(pve)
```


### Model fitting

We use Susie to identify the causal SNP given $Z_j$ and $\pi$. The baseline model for comparison is Lasso.

#### Lasso

For lasso, setting $\lambda=0.3$ seems to be optimal.

```{r, eval=F, echo=F}
library(glmnet)
lambda <- numeric(20L)
for(i in 1:length(lambda)){
  sim.res <- sim_group_pi(X1,pi)
  cvfit <- cv.glmnet(sim.res$X, sim.res$y,penalty.factor = 1/sqrt(sim.res$pi*(1-sim.res$pi)))
  lambda[i] <- cvfit$lambda.min
}
boxplot(lambda)

```


```{r}
set.seed(1234)
sim.res <- sim_group_pi(X1,pi)
plot(abs(sim.res$beta),pch=16,ylab="absolute effect size",xlab="SNP index", main="Oracle")
```


```{r}
library(glmnet)
lasso.fit <- glmnet(sim.res$X, sim.res$y, lambda = 0.2)
plot(abs(lasso.fit$beta), ylab="absolute effect size", xlab="SNP index", main="Lasso")
```


### Lasso with prior weights

Setting `penalty.factor` proportional to $\pi$. In other words, the last group of SNPs only have 4% of penalty of the other group. In this case, lambda is better set at 6.

```{r}
library(glmnet)
net.fit <- glmnet(sim.res$X, sim.res$y, lambda=1, alpha=1,
                  penalty.factor = 1/sqrt(sim.res$pi*(1-sim.res$pi)))
plot(abs(net.fit$beta), ylab="absolute effect size", 
     xlab="SNP index", main="adaptive lasso")
```



#### SuSIE

For the same simulation dataset, SuSIE return five credible sets. Due to strong LD in the loci, PIP for individual SNP was low. 

```{r}
library(susieR)

susie.fit <- susie(sim.res$X, sim.res$y, prior_weights = sim.res$pi,
                   L=sum(sim.res$gamma), coverage = 0.95, standardize = F,
                   intercept = T, compute_univariate_zscore = T)
susie_plot(susie.fit, y='PIP', main="SuSIE with prior", ylim=c(0,1))
```

When SuSIE was run without the grouped prior, more SNPs have similar PIP in the same credible set.

```{r}
susie.fit <- susie(sim.res$X, sim.res$y,L=sum(sim.res$gamma), standardize = F,
                   intercept=T, coverage=0.95)
susie_plot(susie.fit, y='PIP',main="SuSIE without prior", ylim=c(0,1))
```

### Cross validation

We used 5-fold cross validation over the 100 individuals. Evaluation metric in the test set is $R^2$. The two SuSIE models are one with priors and one without, respectively. Note that performance varies a lot depending on the training-testing split. In this particular case, the PVE on full dataset is 3.4%. Two different definitions of $R^2$ are computed. The first one is the squared correlation between $y$ in the test set and $\hat y$. The other is $1-\dfrac{\sum(y-\hat y)^2}{\sum(y-\bar y)^2}$, where $\bar y$ is the mean of $y$ in the training set.

```{r}
calc.r2 <- function(y.test, y.hat, y.mean) {
  1 - sum((y.test-y.hat)**2) / sum((y.test-y.mean)**2)
}
```

```{r}
calc.mse <- function(y.test, y.hat) {
  mean((y.test - y.hat)^2)
}
```


```{r}
set.seed(1234)
sim.res <- sim_group_pi(X, pi)
inds <- sample(rep(1:5,times=20))
#sim.res$X <- apply(sim.res$X,2,as.numeric)
#sim.res$X <- scale(sim.res$X, center=T, scale=T)
dat.cor2 <- matrix(nrow=5,ncol=4)
colnames(dat.cor2) <- c("lasso","lasso.prior","susie","susie.prior")

dat.r2 <- matrix(nrow=5,ncol=4)
colnames(dat.r2) <- c("lasso","lasso.prior","susie","susie.prior")

dat.mse <- matrix(nrow=5,ncol=4)
colnames(dat.mse) <- c("lasso","lasso.prior","susie","susie.prior")

for(i in 1:5) {
  X.train <- sim.res$X[inds!=i,]
  y.train <- sim.res$y[inds!=i]
  X.test <- sim.res$X[inds==i,]
  y.test <- sim.res$y[inds==i]
  
  lasso.fit <- glmnet(X.train, y.train,lambda = 0.3)
  lasso.y <- predict(lasso.fit, X.test)
  dat.cor2[i,"lasso"] <- cor(y.test,lasso.y)**2
  dat.r2[i,"lasso"] <- calc.r2(y.test,lasso.y,mean(y.train))
  dat.mse[i,"lasso"] <- calc.mse(y.test,lasso.y)

  lasso.fit <- glmnet(X.train, y.train,lambda = 1,
                      penalty.factor = 1/sqrt(sim.res$pi*(1-sim.res$pi)))
  lasso.y <- predict(lasso.fit, X.test)
  dat.cor2[i,"lasso.prior"] <- cor(y.test,lasso.y)**2
  dat.r2[i,"lasso.prior"] <- calc.r2(y.test,lasso.y,mean(y.train))
  dat.mse[i,"lasso.prior"] <- calc.mse(y.test,lasso.y)
  
  susie.fit <- susie(X.train, y.train)
  susie.y <- predict(susie.fit, X.test)
  dat.cor2[i,"susie"] <- cor(y.test,susie.y)**2
  dat.r2[i,"susie"] <- calc.r2(y.test,susie.y,mean(y.train))
  dat.mse[i,"susie"] <- calc.mse(y.test,susie.y)
  
  susie.fit <- susie(X.train, y.train, prior_weights = sim.res$pi)
  susie.y <- predict(susie.fit, X.test)
  dat.cor2[i,"susie.prior"] <- cor(y.test,susie.y)**2
  dat.r2[i,"susie.prior"] <- calc.r2(y.test,susie.y,mean(y.train))
  dat.mse[i,"susie.prior"] <- calc.mse(y.test,susie.y)
}

boxplot(dat.cor2, ylab="R2 (squred correlation)", col=2:4)
```

```{r}
boxplot(dat.r2, ylab="R2 (compared to intercept model)", col=2:5)
```


```{r}
boxplot(dat.mse, ylab="Mean squared error", col=2:5)
```



