---
title: "Informative prior"
author: "Lifan Liang"
date: "2025-02-14"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Simulation

### Data generation

We selected 3365 SNPs from a random region (i.e. `chr9:2000000-3000000`) and extracted the corresponding genotype of the 100 cell lines in the neuron stimulation. All SNPs have minor allele frequency (MAF) over 1%. The heatmap below shows the genotype profiles of SNP (column).

```{r}
library(pheatmap)
X <- t(readRDS("data/neuron_stim_genotype_chr9_2e6-3e6.rds")[,-1] )# Each row is a cell line
pheatmap(X,cluster_cols = F)
```



The SNPs were evenly split into 5 groups (673 SNPs per group). SNPs in each group has a different prior for being causal. But the causal SNPs have the same effect size. Let $Z_j$ be the group index for the $j_{th}$ SNP, $\gamma_j$ be whether the $j_{th}$ SNP is causal, and $X_ij$ be the genotype for the $i_{th}$ individual. The genetic effect for the $j_{th}$ SNP ($\beta_j$) is generated as follow:

$$
\gamma_j \sim Bernoulli(\pi_{Z_j})
\\
\beta_j|\gamma_j = 1 \sim N(0,\sigma^2)
\\
\beta_j|\gamma_j = 0 \sim \sigma_0
$$

where $\pi_k$ is the prior of being causal for the $k_{th}$ group, $\sigma$ is the effect size when the SNP is being causal, and $\sigma_0$ is the Dirac delta function.

In this simulation, we set ($\pi_k$) as $\{0.02\%, 0.04\%,0.08\%,0.16\%,0.32\%\}$. For the whole region, 0.124% ($\approx 4$) of the SNPs are expected to be causal. We set $\sigma=0.2$ and $\sigma_e=1.0$. Then we generated gene expression Y as:

$$
\epsilon \sim N(0,\sigma_e^2)
\\
Y_i = \sum_j X_{ij}\beta_j + \epsilon
$$

```{r}
#pi <- rep(c(2,4,8,16,32) * 1e-4, each=ncol(X)/5)
pi <- rep(c(2,4,8,16,32) * 1e-4, 673)

sim_group_pi <- function(X, pi=pi, sigma=0.25, sigma.e=1.0) {
  ### Impose the constraint that there is at least one causal SNP
  N <- 0
  while(N==0) {
    gamma <- rbinom(ncol(X),1,pi)
    N <- sum(gamma)
  }
  beta <- rnorm(ncol(X),sd=sigma) * gamma
  eps <- rnorm(nrow(X),sd=sigma.e)
  Y <- X %*% beta + eps
  list(y=Y, X=X, pi=pi, gamma=gamma, beta=beta, eps=eps)
}

```

PVE varies because the genetic component of $var(Y)$ depends on the effect size and the allele frequency of causal SNPs. Mostly, the total PVE was less than 20%.

```{r}
set.seed(1234)
pve <- numeric(100L)
#rand.cor <- numeric(100L)
for(i in 1:length(pve)) {
  sim.res <- sim_group_pi(X,pi)
  pve[i] <- 1 - sum(sim.res$eps**2) / sum((sim.res$y - mean(sim.res$y))**2)
  #rand.cor[i] <- max(abs(cor(sim.res$eps, sim.res$dat[,-1][,gamma!=0])))
}
boxplot(pve)
```


### Model fitting

We use Susie to identify the causal SNP given $Z_j$ and $\pi$. The baseline model for comparison is Lasso.

#### Lasso

For lasso, setting $\lambda=0.3$ seems to be optimal.

```{r, eval=F, echo=F}
library(glmnet)
lambda <- numeric(20L)
for(i in 1:length(lambda)){
  sim.res <- sim_group_pi(X,pi)
  cvfit <- cv.glmnet(sim.res$X, sim.res$y)
  lambda[i] <- cvfit$lambda.min
}
boxplot(lambda)

```


```{r}
set.seed(22)
sim.res <- sim_group_pi(X,pi)
plot(abs(sim.res$beta),pch=16,ylab="absolute effect size",xlab="SNP index")
```


```{r}
library(glmnet)
fit <- glmnet(sim.res$X, sim.res$y,lambda = 0.3)
plot(abs(fit$beta), ylab="absolute beta from lasso", xlab="SNP index")
```

#### SuSIE

For the same simulation dataset, SuSIE return five credible sets. Due to strong LD in the loci, PIP for individual SNP was low. 

```{r}
library(susieR)

X1 <- apply(sim.res$X,2,as.numeric)
susie.fit <- susie(X1, sim.res$y, prior_weights = sim.res$pi,
                   L=sum(sim.res$gamma),standardize = F, coverage = 0.95)
susie_plot(susie.fit, y='PIP')
```

When SuSIE was run without the grouped prior, more SNPs have similar PIP in the same credible set.

```{r}
susie.fit <- susie(X1, sim.res$y, coverage = 0.95,
                   L=sum(sim.res$gamma),standardize = F)
susie_plot(susie.fit, y='PIP')
```

### Cross validation

We used 5-fold cross validation over the 100 individuals. Evaluation metric in the test set is $R^2$. The two SuSIE models is one with priors and one without. Note that performance varies a lot depending on the training-testing split. In this particular case, the PVE on full dataset is 17.5%. Two different definitions of $R^2$ are computed. The first one is the squared correlation between $y$ in the test set and $\hat y$. The other is $1-\dfrac{\sum(y-\hat y)^2}{\sum(y-\bar y)^2}$, where $\bar y$ is the mean of $y$ in the training set.

```{r}
calc.r2 <- function(y.test, y.hat, y.mean) {
  1 - sum((y.test-y.hat)**2) / sum((y.test-y.mean)**2)
}
```

```{r}
set.seed(22)
sim.res <- sim_group_pi(X, pi)
inds <- sample(rep(1:5,times=20))
sim.res$X <- apply(sim.res$X,2,as.numeric)
dat.r2 <- matrix(nrow=5,ncol=3)
colnames(dat.r2) <- c("lasso","susie","susie.prior")

for(i in 1:5) {
  X.train <- sim.res$X[inds!=i,]
  y.train <- sim.res$y[inds!=i]
  X.test <- sim.res$X[inds==i,]
  y.test <- sim.res$y[inds==i]
  
  lasso.fit <- glmnet(X.train, y.train,lambda = 0.3)
  lasso.y <- predict(lasso.fit, X.test)
  dat.r2[i,"lasso"] <- cor(y.test,lasso.y)**2
  
  susie.fit <- susie(X.train, y.train, L=5, standardize = F)
  susie.y <- predict(susie.fit, X.test)
  dat.r2[i,"susie"] <- cor(y.test,susie.y)**2
  
  susie.fit <- susie(X.train, y.train, prior_weights = sim.res$pi, L=5, standardize = F)
  susie.y <- predict(susie.fit, X.test)
  dat.r2[i,"susie.prior"] <- cor(y.test,susie.y)**2
}

boxplot(dat.r2, ylab="R2 (squred correlation)", col=2:4)
```

```{r}
dat.r2 <- matrix(nrow=5,ncol=3)
colnames(dat.r2) <- c("lasso","susie","susie.prior")

for(i in 1:5) {
  X.train <- sim.res$X[inds!=i,]
  y.train <- sim.res$y[inds!=i]
  X.test <- sim.res$X[inds==i,]
  y.test <- sim.res$y[inds==i]
  
  lasso.fit <- glmnet(X.train, y.train,lambda = 0.3)
  lasso.y <- predict(lasso.fit, X.test)
  dat.r2[i,"lasso"] <- calc.r2(y.test,lasso.y,mean(y.train))
  
  susie.fit <- susie(X.train, y.train, L=5, standardize = F)
  susie.y <- predict(susie.fit, X.test, "response")
  dat.r2[i,"susie"] <- calc.r2(y.test,susie.y,mean(y.train))
  
  susie.fit <- susie(X.train, y.train, prior_weights = sim.res$pi, L=5, standardize = F)
  susie.y <- predict(susie.fit, X.test, "response")
  dat.r2[i,"susie.prior"] <- calc.r2(y.test,susie.y,mean(y.train))
}

boxplot(dat.r2, ylab="R2 (compared to intercept model)", col=2:4)
```

